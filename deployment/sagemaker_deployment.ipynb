{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Calculator Model Deployment\n",
    "\n",
    "This notebook deploys the calculator model to SageMaker for real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "import tarfile\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint cleanup function\n",
    "def delete_existing_endpoint(endpoint_name):\n",
    "    import time\n",
    "    try:\n",
    "        sagemaker_client = boto3.client('sagemaker')\n",
    "        sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "        print(f'Deleting existing endpoint: {endpoint_name}')\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "                print('Waiting for endpoint deletion...')\n",
    "                time.sleep(10)\n",
    "            except:\n",
    "                print('Endpoint deleted successfully')\n",
    "                break\n",
    "    except:\n",
    "        print(f'No existing endpoint found: {endpoint_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SageMaker session and get role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "print(f\"SageMaker role: {role}\")\n",
    "print(f\"Default bucket: {sagemaker_session.default_bucket()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing endpoint before deployment\n",
    "delete_existing_endpoint('math-calculator-endpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model package\n",
    "os.makedirs('code', exist_ok=True)\n",
    "\n",
    "# Copy model files\n",
    "import shutil\n",
    "shutil.copy('../src/calculator_model.py', 'code/')\n",
    "shutil.copy('../src/inference.py', 'code/')\n",
    "\n",
    "# Create model.tar.gz\n",
    "with tarfile.open('model.tar.gz', 'w:gz') as tar:\n",
    "    tar.add('code', arcname='code')\n",
    "\n",
    "print(\"Model package created: model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model to S3\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "model_artifacts = sagemaker_session.upload_data(\n",
    "    path='model.tar.gz',\n",
    "    bucket=bucket,\n",
    "    key_prefix='calculator-model'\n",
    ")\n",
    "\n",
    "print(f\"Model uploaded to: {model_artifacts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch model\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_artifacts,\n",
    "    role=role,\n",
    "    entry_point='inference.py',\n",
    "    source_dir=None,\n",
    "    framework_version='1.12',\n",
    "    py_version='py38'\n",
    ")\n",
    "\n",
    "print(\"PyTorch model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy to endpoint\n",
    "predictor = pytorch_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium',\n",
    "    endpoint_name='math-calculator-endpoint'\n",
    ")\n",
    "\n",
    "print(f\"Model deployed to endpoint: {predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure predictor for JSON\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "# Test the endpoint\n",
    "test_data = {\n",
    "    \"operation\": \"add\",\n",
    "    \"a\": 10,\n",
    "    \"b\": 5\n",
    "}\n",
    "\n",
    "try:\n",
    "    result = predictor.predict(test_data)\n",
    "    print(f\"Test result: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple operations\n",
    "test_cases = [\n",
    "    {\"operation\": \"add\", \"a\": 10, \"b\": 5},\n",
    "    {\"operation\": \"multiply\", \"a\": 4, \"b\": 3},\n",
    "    {\"operation\": \"sqrt\", \"a\": 16},\n",
    "    {\"operation\": \"sin\", \"a\": 90}\n",
    "]\n",
    "\n",
    "for test in test_cases:\n",
    "    result = predictor.predict(test)\n",
    "    print(f\"Input: {test} -> Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging function\n",
    "def get_endpoint_logs(endpoint_name):\n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    logs_client = boto3.client('logs')\n",
    "    log_group = f'/aws/sagemaker/Endpoints/{endpoint_name}'\n",
    "    \n",
    "    try:\n",
    "        end_time = datetime.now()\n",
    "        start_time = end_time - timedelta(minutes=10)\n",
    "        \n",
    "        response = logs_client.filter_log_events(\n",
    "            logGroupName=log_group,\n",
    "            startTime=int(start_time.timestamp() * 1000),\n",
    "            endTime=int(end_time.timestamp() * 1000)\n",
    "        )\n",
    "        \n",
    "        print(f'=== Endpoint Logs for {endpoint_name} ===')\n",
    "        for event in response['events']:\n",
    "            timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "            print(f'[{timestamp}] {event[\"message\"]}')\n",
    "    except Exception as e:\n",
    "        print(f'Could not fetch logs: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View endpoint logs\n",
    "get_endpoint_logs(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save endpoint name for later use\n",
    "endpoint_name = predictor.endpoint_name\n",
    "print(f\"Endpoint name: {endpoint_name}\")\n",
    "\n",
    "# Save to file\n",
    "with open('endpoint_config.json', 'w') as f:\n",
    "    json.dump({'endpoint_name': endpoint_name}, f)\n",
    "    \n",
    "print(\"Endpoint configuration saved to endpoint_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup endpoint (run when done)\n",
    "# predictor.delete_endpoint()\n",
    "# print('Endpoint deleted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}